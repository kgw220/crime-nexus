{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c2a40d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a notebook to walkthrough the process of clustering the combined data.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import hdbscan\n",
    "import numpy\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7989ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dispatch_date       dispatch_time            address_block        lat  \\\n",
      "0    2025-05-02 2025-07-08 23:44:00      1100 BLOCK S 4TH ST  39.934248   \n",
      "2    2025-04-23 2025-07-08 18:32:00     1700 BLOCK N 32ND ST  39.983588   \n",
      "3    2025-04-24 2025-07-08 00:47:00  1300 BLOCK W Venango St  40.007425   \n",
      "4    2025-02-26 2025-07-08 20:16:00      400 BLOCK N 35TH ST  39.961642   \n",
      "5    2025-04-13 2025-07-08 03:15:00      5100 BLOCK N 5TH ST  40.029310   \n",
      "\n",
      "         lon  district_01  district_02  district_03  district_05  district_06  \\\n",
      "0 -75.150833        False        False         True        False        False   \n",
      "2 -75.186199        False        False        False        False        False   \n",
      "3 -75.149843        False        False        False        False        False   \n",
      "4 -75.192723        False        False        False        False        False   \n",
      "5 -75.132056        False        False        False        False        False   \n",
      "\n",
      "   ...  max_temp_f  min_temp_f  pop_total  income_median  median_age  \\\n",
      "0  ...        86.0        59.0     4306.0        83508.0        36.4   \n",
      "2  ...        77.0        54.0     4140.0        37431.0        35.5   \n",
      "3  ...        79.0        50.0     2807.0        49115.0        44.4   \n",
      "4  ...        61.0        35.0     7525.0        38976.0        20.0   \n",
      "5  ...        62.0        42.0     7170.0        60892.0        34.2   \n",
      "\n",
      "   poverty_rate  vacancy_rate  renter_occupancy_rate  area_sq_km  \\\n",
      "0      0.204366      0.032818               0.440136    0.398697   \n",
      "2      0.401691      0.130470               0.550792    0.453221   \n",
      "3      0.259708      0.204270               0.464222    0.508176   \n",
      "4      0.205050      0.104931               0.880205    0.436319   \n",
      "5      0.217434      0.042004               0.310769    0.717845   \n",
      "\n",
      "   pop_density_sq_km  \n",
      "0       10800.181592  \n",
      "2        9134.616445  \n",
      "3        5523.676836  \n",
      "4       17246.555846  \n",
      "5        9988.228657  \n",
      "\n",
      "[5 rows x 88 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import data from previous notebook\n",
    "df = pd.read_pickle(\"data/merged_data_2022-07-08_to_2025-07-07.pkl\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f958fd",
   "metadata": {},
   "source": [
    "The first significant step is to scale our data, as clustering is based on distance. This is to avoid\n",
    "features that are naturally greater in range, take higher importance/precedence when clustered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092cebb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dispatch_date       dispatch_time            address_block       lat  \\\n",
      "0    2025-05-02 2025-07-08 23:44:00      1100 BLOCK S 4TH ST -1.407757   \n",
      "2    2025-04-23 2025-07-08 18:32:00     1700 BLOCK N 32ND ST -0.323392   \n",
      "3    2025-04-24 2025-07-08 00:47:00  1300 BLOCK W Venango St  0.200477   \n",
      "4    2025-02-26 2025-07-08 20:16:00      400 BLOCK N 35TH ST -0.805715   \n",
      "5    2025-04-13 2025-07-08 03:15:00      5100 BLOCK N 5TH ST  0.681454   \n",
      "\n",
      "        lon  district_01  district_02  district_03  district_05  district_06  \\\n",
      "0 -0.066541        False        False         True        False        False   \n",
      "2 -0.628440        False        False        False        False        False   \n",
      "3 -0.050807        False        False        False        False        False   \n",
      "4 -0.732081        False        False        False        False        False   \n",
      "5  0.231798        False        False        False        False        False   \n",
      "\n",
      "   ...  max_temp_f  min_temp_f  pop_total  income_median  median_age  \\\n",
      "0  ...    1.028564    0.511307  -0.125704       0.135994    0.040246   \n",
      "2  ...    0.508399    0.198620  -0.222344       0.135475   -0.091601   \n",
      "3  ...    0.623991   -0.051529  -0.998372       0.135607    1.212221   \n",
      "4  ...   -0.416339   -0.989590   1.748291       0.135493   -2.362304   \n",
      "5  ...   -0.358543   -0.551829   1.541621       0.135739   -0.282047   \n",
      "\n",
      "   poverty_rate  vacancy_rate  renter_occupancy_rate  area_sq_km  \\\n",
      "0     -0.314030     -1.165121              -0.301037   -0.628530   \n",
      "2      1.162551      0.390956               0.270198   -0.529468   \n",
      "3      0.100093      1.566956              -0.176699   -0.429624   \n",
      "4     -0.308913     -0.016002               1.970707   -0.560176   \n",
      "5     -0.216245     -1.018731              -0.968858   -0.048689   \n",
      "\n",
      "   pop_density_sq_km  \n",
      "0           0.803145  \n",
      "2           0.351528  \n",
      "3          -0.627576  \n",
      "4           2.551075  \n",
      "5           0.582984  \n",
      "\n",
      "[5 rows x 88 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize StandardScaler and config it to output a DataFrame\n",
    "scaler = StandardScaler()\n",
    "scaler.set_output(transform='pandas')\n",
    "\n",
    "# Extract the columns to scale\n",
    "numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "# NOTE: I do not want to scale the sinusoidal features as they are already in the desired range\n",
    "cols_to_scale = [\n",
    "    col for col in numeric_cols\n",
    "    if '_sin' not in col and '_cos' not in col\n",
    "]\n",
    "\n",
    "# Fit and transform the data\n",
    "df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n",
    "\n",
    "# Print the scaled data as sanity check\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2d4dc9",
   "metadata": {},
   "source": [
    "Now, the data is ready for applying UMAP. This is a non-linear dimensionality\n",
    "reduction algorithm, based on topology (allowing it to capture those non-linear patterns). This is\n",
    "used, as clustering our data with over 80 columns can easily lead to the curse of dimensionality,\n",
    "leading to much higher computational time and overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
